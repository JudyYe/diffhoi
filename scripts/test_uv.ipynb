{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pytorch3d.io import load_obj\n",
    "from jutils import mesh_utils, image_utils\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import os.path as osp\n",
    "save_dir = '/private/home/yufeiy2/vhoi/output/neurecon_out/'\n",
    "mesh_file = '/private/home/yufeiy2/vhoi/output/neurecon_out/open_hand_uv.obj'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer import TexturesUV, TexturesVertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn = load_obj(mesh_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Properties(normals=None, verts_uvs=tensor([[0.5197, 0.6239],\n",
       "        [0.4949, 0.6418],\n",
       "        [0.4846, 0.6176],\n",
       "        ...,\n",
       "        [0.3520, 0.4942],\n",
       "        [0.3550, 0.4921],\n",
       "        [0.3534, 0.4891]]), material_colors=None, texture_images=None, texture_atlas=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1538, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn[1].textures_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.zeros([4, 4, 3]); image[..., 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = Meshes([rtn[0]], [rtn[1].verts_idx], TexturesUV(\n",
    "    [image], rtn[1].textures_idx[None], rtn[2].verts_uvs[None]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = mesh_utils.render_geom_rot(meshes.cuda(), scale_geom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to  /private/home/yufeiy2/vhoi/output/neurecon_out/tmp.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"/private/home/yufeiy2/vhoi/output/neurecon_out/tmp.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_utils.save_gif(image_list, osp.join(save_dir, 'tmp'))\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"%s.gif\">' % osp.join(save_dir, 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_verts = Meshes([rtn[0]], [rtn[1].verts_idx], TexturesVertex(\n",
    "    torch.ones_like(rtn[0])[None]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to  /private/home/yufeiy2/vhoi/output/neurecon_out/tmp2.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"/private/home/yufeiy2/vhoi/output/neurecon_out/tmp2.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list = mesh_utils.render_geom_rot(mesh_verts.cuda(), scale_geom=True)\n",
    "image_utils.save_gif(image_list, osp.join(save_dir, 'tmp2'))\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"%s.gif\">' % osp.join(save_dir, 'tmp2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4564, -0.1127, -0.5810],\n",
       "        [-0.5482, -0.0392, -0.6246],\n",
       "        [-0.4965,  0.0151, -0.5381],\n",
       "        ...,\n",
       "        [-0.2917, -0.2082, -1.0127],\n",
       "        [-0.2111, -0.2434, -0.9832],\n",
       "        [-0.4597, -0.1425, -0.9556]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/yufeiy2/hoi/exts/manopth/manopth/manolayer.py:72: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  torch.Tensor(smpl_data['betas'].r).unsqueeze(0))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "maps must be on the same device as verts/faces uvs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/private/home/yufeiy2/vhoi/neurecon/scripts/test_uv.ipynb Cell 14'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair-vs/private/home/yufeiy2/vhoi/neurecon/scripts/test_uv.ipynb#ch0000013vscode-remote?line=4'>5</a>\u001b[0m wrapper \u001b[39m=\u001b[39m ManopthWrapper()\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdevfair-vs/private/home/yufeiy2/vhoi/neurecon/scripts/test_uv.ipynb#ch0000013vscode-remote?line=5'>6</a>\u001b[0m hA \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones([\u001b[39m1\u001b[39m, \u001b[39m45\u001b[39m])\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdevfair-vs/private/home/yufeiy2/vhoi/neurecon/scripts/test_uv.ipynb#ch0000013vscode-remote?line=6'>7</a>\u001b[0m hand_mesh, _ \u001b[39m=\u001b[39m wrapper(\u001b[39mNone\u001b[39;49;00m, hA, texture\u001b[39m=\u001b[39;49mimage[\u001b[39mNone\u001b[39;49;00m])\n",
      "File \u001b[0;32m~/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=724'>725</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=725'>726</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=726'>727</a>\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=727'>728</a>\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=728'>729</a>\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=729'>730</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/torch/nn/modules/module.py?line=730'>731</a>\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/vhoi/neurecon/scripts/../utils/hand_utils.py:166\u001b[0m, in \u001b[0;36mManopthWrapper.forward\u001b[0;34m(self, glb_se3, art_pose, axisang, trans, return_mesh, mode, texture, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/vhoi/neurecon/scripts/../utils/hand_utils.py?line=163'>164</a>\u001b[0m     textures \u001b[39m=\u001b[39m TexturesVertex(textures)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/vhoi/neurecon/scripts/../utils/hand_utils.py?line=164'>165</a>\u001b[0m \u001b[39melif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(texture):\n\u001b[0;32m--> <a href='file:///private/home/yufeiy2/vhoi/neurecon/scripts/../utils/hand_utils.py?line=165'>166</a>\u001b[0m     textures \u001b[39m=\u001b[39m TexturesUV(texture, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfaces_uv, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverts_uv)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/vhoi/neurecon/scripts/../utils/hand_utils.py?line=167'>168</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/vhoi/neurecon/scripts/../utils/hand_utils.py?line=168'>169</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/lasr/lib/python3.8/site-packages/pytorch3d/renderer/mesh/textures.py:722\u001b[0m, in \u001b[0;36mTexturesUV.__init__\u001b[0;34m(self, maps, faces_uvs, verts_uvs, padding_mode, align_corners, sampling_mode)\u001b[0m\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/pytorch3d/renderer/mesh/textures.py?line=718'>719</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maps_padded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_maps_padded(maps)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/pytorch3d/renderer/mesh/textures.py?line=720'>721</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maps_padded\u001b[39m.\u001b[39mdevice \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m--> <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/pytorch3d/renderer/mesh/textures.py?line=721'>722</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmaps must be on the same device as verts/faces uvs.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///private/home/yufeiy2/.conda/envs/lasr/lib/python3.8/site-packages/pytorch3d/renderer/mesh/textures.py?line=723'>724</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_N,), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbool, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mValueError\u001b[0m: maps must be on the same device as verts/faces uvs."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.hand_utils import ManopthWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wrapper = ManopthWrapper().cuda()\n",
    "hA = torch.ones([2, 45]).cuda()\n",
    "hand_mesh, _ = wrapper(None, hA, texture=image[None].repeat(2, 1, 1, 1).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to  /private/home/yufeiy2/vhoi/output/neurecon_out/tmp3.gif\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"/private/home/yufeiy2/vhoi/output/neurecon_out/tmp3.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list = mesh_utils.render_geom_rot(hand_mesh.cuda(), scale_geom=True)\n",
    "image_utils.save_gif(image_list, osp.join(save_dir, 'tmp3'))\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<img src=\"%s.gif\">' % osp.join(save_dir, 'tmp3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "141dab72628f1cbfba27fb16ef0f825dd45c75155b74eeb65a576f08db82f8b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('lasr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
