resume: True

submitit_dir: ${exp_dir}/submitit_train_logs/

world_size: 1
rank: 0
dist_url: tcp://localhost:10001
dist_backend: nccl
port: 10001
node: localhost


multiprocessing_distributed: False
distributed: True
seed:
gpu:
ngpu: 1
workers: 8
mem_gb: 256
gpu_mem_gb: '20G'

slurm: False
slurm_partition: abhinavlong,shubhamlong,all
slurm_timeout: 30 # 2880  # in min 1440 is one day
nodelist: ""
exclude_nodes: ""

